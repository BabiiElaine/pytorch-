{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, info_csv, image_list, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: path to image directory.\n",
    "            info_csv: path to the csv file containing image indexes\n",
    "                with corresponding labels.\n",
    "            image_list: path to the txt file contains image names to training/validation set\n",
    "            transform: optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        label_info = pd.read_csv(info_csv)\n",
    "        image_file = open(image_list).readlines()\n",
    "        self.data_dir = data_dir\n",
    "        self.image_file = image_file\n",
    "        self.label_info = label_info\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of item\n",
    "        Returns:\n",
    "            image and its labels\n",
    "        \"\"\"\n",
    "        image_name = self.image_file[index].strip('\\n')\n",
    "        raw_label = self.label_info.loc[self.label_info['Image_index'] == image_name]\n",
    "        label = raw_label.iloc[:,0]\n",
    "        image_name = os.path.join(self.data_dir, image_name)\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "      # 声明带有模型参数的层，这里声明了两个全连接层\n",
    "  def __init__(self, **kwargs):\n",
    "    # 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "    super(MLP, self).__init__(**kwargs)\n",
    "    self.hidden = torch.nn.Linear(784, 256)\n",
    "    self.activation = torch.nn.ReLU()\n",
    "    self.output = torch.nn.Linear(256,10)\n",
    "    \n",
    "   # 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出\n",
    "  def forward(self, x):\n",
    "    o = self.activation(self.hidden(x))\n",
    "    return self.output(o)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1382,  0.1880, -0.1514, -0.1725, -0.1281,  0.0282, -0.1136,  0.1002,\n",
       "          0.2495,  0.0147],\n",
       "        [-0.0099,  0.0690, -0.1866, -0.2335, -0.0576, -0.1825, -0.1785,  0.1205,\n",
       "          0.1481,  0.0777]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2,784)\n",
    "net = MLP()\n",
    "print(net)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 不含模型参数的层\n",
    "class MyLayer(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    def forward(self, x):\n",
    "        return x - x.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = MyLayer()\n",
    "layer(torch.tensor([1, 2, 3, 4, 5], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyListDense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## 含模型参数的层\n",
    "class MyListDense(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyListDense, self).__init__()\n",
    "        self.params = torch.nn.ParameterList([torch.nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        self.params.append(torch.nn.Parameter(torch.randn(4, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            x = torch.mm(x, self.params[i])    ## torch.mm是两个矩阵相乘，即两个二维的张量相乘\n",
    "        return x\n",
    "net = MyListDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDictDense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyDictDense(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDictDense, self).__init__()\n",
    "        self.params = torch.nn.ParameterDict({\n",
    "                'linear1': torch.nn.Parameter(torch.randn(4, 4)),\n",
    "                'linear2': torch.nn.Parameter(torch.randn(4, 1))\n",
    "        })\n",
    "        self.params.update({'linear3': torch.nn.Parameter(torch.randn(4, 2))}) # 新增\n",
    "\n",
    "    def forward(self, x, choice='linear1'):\n",
    "        return torch.mm(x, self.params[choice])\n",
    "\n",
    "net = MyDictDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积运算（二维互相关）\n",
    "def corr2d(X, K): \n",
    "    h, w = K.shape\n",
    "    X, K = X.float(), K.float()\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "# 二维卷积层\n",
    "class Conv2D(torch.nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:]) # 排除不关心的前两维:批量和通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 池化层\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]], dtype=torch.float)\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LeNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 输入图像channel：1；输出channel：6；5x5卷积核\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2x2 Max pooling\n",
    "        x = torch.nn.functional.max_pool2d(torch.nn.functional.relu(self.conv1(x)), (2, 2))\n",
    "        # 如果是方阵,则可以只使用一个数字进行定义\n",
    "        x = torch.nn.functional.max_pool2d(torch.nn.functional.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # 除去批处理维度的其他所有维度\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0899, -0.0449,  0.0404, -0.0582,  0.0121, -0.0321, -0.0515, -0.1379,\n",
      "          0.0067,  0.0130]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn((1, 1, 32, 32), dtype=torch.float32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 随机初始化\n",
    "conv = torch.nn.Conv2d(1,3,3)\n",
    "linear = torch.nn.Linear(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2208,  0.0873, -0.2846,  0.2538, -0.0927,  0.2229,  0.1772,  0.2948,\n",
       "          0.0576, -0.2700]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看随机初始化的conv参数\n",
    "conv.weight.data\n",
    "# 查看linear的参数\n",
    "linear.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2132, -0.0229, -0.0207],\n",
       "          [-0.3492, -0.7208,  0.0587],\n",
       "          [-0.0481,  0.4208,  0.1236]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3960,  0.6066, -0.2484],\n",
       "          [ 0.1723,  0.4524, -0.1630],\n",
       "          [ 0.4282, -0.7684, -0.2818]]],\n",
       "\n",
       "\n",
       "        [[[-0.3068, -0.1742, -0.4688],\n",
       "          [ 0.2532, -0.2982, -0.3573],\n",
       "          [-0.5436, -0.4671, -0.3889]]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.kaiming_normal_(conv.weight.data)\n",
    "conv.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000, 0.3000,\n",
       "         0.3000]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.constant_(linear.weight.data,0.3)\n",
    "linear.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化函数的封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(self):\n",
    "    for m in self.modules():\n",
    "\t\t# 判断是否属于Conv2d\n",
    "        if isinstance(m, torch.nn.Conv2d):     ## 通常使用isinstance来进行判断模块\n",
    "            torch.nn.init.xavier_normal_(m.weight.data)\n",
    "\t\t\t# 判断是否有偏置\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.constant_(m.bias.data,0.3)\n",
    "        elif isinstance(m, torch.nn.Linear):\n",
    "            torch.nn.init.normal_(m.weight.data, 0.1)\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias.data)\n",
    "        elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zeros_()\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.1168,  0.0915, -0.1900],\n",
      "          [-0.2221, -0.0107,  0.1153],\n",
      "          [-0.3275, -0.1296,  0.3117]]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0806], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2741,  0.0491,  0.2559, -0.2027,  0.0238,  0.2721,  0.2606, -0.2879,\n",
      "          0.2441,  0.1189]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0263], requires_grad=True)]\n",
      "-------初始化-------\n",
      "[Parameter containing:\n",
      "tensor([[[[ 0.4471,  0.2237,  0.1045],\n",
      "          [ 0.1153, -0.1314, -0.3274],\n",
      "          [-0.4388,  0.3325, -0.1100]]]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3000], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.5033,  1.4954, -0.6214, -0.0831, -0.0945,  0.5557, -2.4865, -0.3636,\n",
      "         -1.6572,  0.0210]], requires_grad=True), Parameter containing:\n",
      "tensor([0.], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# 模型的定义\n",
    "class MLP(torch.nn.Module):\n",
    "  # 声明带有模型参数的层，这里声明了两个全连接层\n",
    "  def __init__(self, **kwargs):\n",
    "    # 调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "    super(MLP, self).__init__(**kwargs)\n",
    "    self.hidden = torch.nn.Conv2d(1,1,3)\n",
    "    self.act = torch.nn.ReLU()\n",
    "    self.output = torch.nn.Linear(10,1)\n",
    "    \n",
    "   # 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出\n",
    "  def forward(self, x):\n",
    "    o = self.act(self.hidden(x))\n",
    "    return self.output(o)\n",
    "\n",
    "mlp = MLP()\n",
    "print(list(mlp.parameters()))\n",
    "print(\"-------初始化-------\")\n",
    "\n",
    "initialize_weights(mlp)\n",
    "print(list(mlp.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCELoss损失函数的计算结果为 tensor(0.6753, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m = torch.nn.Sigmoid()\n",
    "loss = torch.nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "output = loss(m(input), target)\n",
    "output.backward()\n",
    "print('BCELoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss损失函数的计算结果为 tensor(2.4537, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print('CrossEntropyLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1损失函数的计算结果为 tensor(1.3191, grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.L1Loss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print('L1损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE损失函数的计算结果为 tensor(1.3164, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print('MSE损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmoothL1Loss损失函数的计算结果为 tensor(0.6853, grad_fn=<SmoothL1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.SmoothL1Loss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print('SmoothL1Loss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = torch.linspace(-10, 10, steps=5000)\n",
    "target = torch.zeros_like(inputs)\n",
    "\n",
    "loss_f_smooth = torch.nn.SmoothL1Loss(reduction='none')\n",
    "loss_smooth = loss_f_smooth(inputs, target)\n",
    "loss_f_l1 = torch.nn.L1Loss(reduction='none')\n",
    "loss_l1 = loss_f_l1(inputs,target)\n",
    "\n",
    "plt.plot(inputs.numpy(), loss_smooth.numpy(), label='Smooth L1 Loss')\n",
    "plt.plot(inputs.numpy(), loss_l1, label='L1 loss')\n",
    "plt.xlabel('x_i - y_i')\n",
    "plt.ylabel('loss value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoissonNLLLoss损失函数的计算结果为 tensor(2.1372, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.PoissonNLLLoss()\n",
    "log_input = torch.randn(5, 2, requires_grad=True)\n",
    "target = torch.randn(5, 2)\n",
    "output = loss(log_input, target)\n",
    "output.backward()\n",
    "print('PoissonNLLLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLDivLoss损失函数的计算结果为 tensor(-0.3335)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:2747: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[0.5, 0.3, 0.2], [0.2, 0.3, 0.5]])\n",
    "target = torch.tensor([[0.9, 0.05, 0.05], [0.1, 0.7, 0.2]], dtype=torch.float)\n",
    "loss = torch.nn.KLDivLoss()\n",
    "output = loss(inputs,target)\n",
    "\n",
    "print('KLDivLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarginRankingLoss损失函数的计算结果为 tensor(0.8093, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MarginRankingLoss()\n",
    "input1 = torch.randn(3, requires_grad=True)\n",
    "input2 = torch.randn(3, requires_grad=True)\n",
    "target = torch.randn(3).sign()\n",
    "output = loss(input1, input2, target)\n",
    "output.backward()\n",
    "\n",
    "print('MarginRankingLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelMarginLoss损失函数的计算结果为 tensor(0.4500)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MultiLabelMarginLoss()\n",
    "x = torch.FloatTensor([[0.9, 0.2, 0.4, 0.8]])\n",
    "# for target y, only consider labels 3 and 0, not after label -1\n",
    "y = torch.LongTensor([[3, 0, -1, 1]])# 真实的分类是，第3类和第0类\n",
    "output = loss(x, y)\n",
    "\n",
    "print('MultiLabelMarginLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftMarginLoss损失函数的计算结果为 tensor(0.6764)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[0.3, 0.7], [0.5, 0.5]])  # 两个样本，两个神经元\n",
    "target = torch.tensor([[-1, 1], [1, -1]], dtype=torch.float)  # 该 loss 为逐个神经元计算，需要为每个神经元单独设置标签\n",
    "\n",
    "loss_f = torch.nn.SoftMarginLoss()\n",
    "output = loss_f(inputs, target)\n",
    "\n",
    "print('SoftMarginLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiMarginLoss损失函数的计算结果为 tensor(0.6000)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[0.3, 0.7], [0.5, 0.5]]) \n",
    "target = torch.tensor([0, 1], dtype=torch.long) \n",
    "\n",
    "loss_f = torch.nn.MultiMarginLoss()\n",
    "output = loss_f(inputs, target)\n",
    "\n",
    "print('MultiMarginLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TripletMarginLoss损失函数的计算结果为 tensor(1.0314, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "triplet_loss = torch.nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "anchor = torch.randn(100, 128, requires_grad=True)\n",
    "positive = torch.randn(100, 128, requires_grad=True)\n",
    "negative = torch.randn(100, 128, requires_grad=True)\n",
    "output = triplet_loss(anchor, positive, negative)\n",
    "output.backward()\n",
    "print('TripletMarginLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HingEmbeddingLoss损失函数的计算结果为 tensor(0.7667)\n"
     ]
    }
   ],
   "source": [
    "loss_f = torch.nn.HingeEmbeddingLoss()\n",
    "inputs = torch.tensor([[1., 0.8, 0.5]])\n",
    "target = torch.tensor([[1, 1, -1]])\n",
    "output = loss_f(inputs,target)\n",
    "\n",
    "print('HingEmbeddingLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CosineEmbeddingLoss损失函数的计算结果为 tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "loss_f = torch.nn.CosineEmbeddingLoss()\n",
    "inputs_1 = torch.tensor([[0.3, 0.5, 0.7], [0.3, 0.5, 0.7]])\n",
    "inputs_2 = torch.tensor([[0.1, 0.3, 0.5], [0.1, 0.3, 0.5]])\n",
    "target = torch.tensor([1, -1], dtype=torch.float)\n",
    "output = loss_f(inputs_1,inputs_2,target)\n",
    "\n",
    "print('CosineEmbeddingLoss损失函数的计算结果为',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTCLoss损失函数的计算结果为 tensor(11.5525, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Target are to be padded\n",
    "T = 50      # Input sequence length\n",
    "C = 20      # Number of classes (including blank)\n",
    "N = 16      # Batch size\n",
    "S = 30      # Target sequence length of longest target in batch (padding length)\n",
    "S_min = 10  # Minimum target length, for demonstration purposes\n",
    "\n",
    "# Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "\n",
    "# Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
    "\n",
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
    "ctc_loss = torch.nn.CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "# Target are to be un-padded\n",
    "T = 50      # Input sequence length\n",
    "C = 20      # Number of classes (including blank)\n",
    "N = 16      # Batch size\n",
    "\n",
    "# Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "\n",
    "# Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "target_lengths = torch.randint(low=1, high=T, size=(N,), dtype=torch.long)\n",
    "target = torch.randint(low=1, high=C, size=(sum(target_lengths),), dtype=torch.long)\n",
    "ctc_loss = torch.nn.CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "\n",
    "print('CTCLoss损失函数的计算结果为',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data of weight before step:\n",
      "tensor([[ 0.5512,  0.2066],\n",
      "        [-0.7554,  0.9012]])\n",
      "The grad of weight before step:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "The data of weight after step:\n",
      "tensor([[ 0.4512,  0.1066],\n",
      "        [-0.8554,  0.8012]])\n",
      "The grad of weight after step:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "The grad of weight after optimizer.zero_grad():\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "optimizer.params_group is \n",
      "[{'params': [tensor([[ 0.4512,  0.1066],\n",
      "        [-0.8554,  0.8012]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}]\n",
      "weight in optimizer:2599848718064\n",
      "weight in weight:2599848718064\n",
      "\n",
      "optimizer.param_groups is\n",
      "[{'params': [tensor([[ 0.4512,  0.1066],\n",
      "        [-0.8554,  0.8012]], requires_grad=True)], 'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}, {'params': [tensor([[ 0.0042, -0.5098, -1.4636],\n",
      "        [-0.1872,  0.1309,  0.8817],\n",
      "        [-0.7516, -0.5788,  1.9815]], requires_grad=True)], 'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0}]\n",
      "state_dict before step:\n",
      " {'state': {0: {'momentum_buffer': tensor([[1., 1.],\n",
      "        [1., 1.]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [1]}]}\n",
      "state_dict after step:\n",
      " {'state': {0: {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
      "        [0.0052, 0.0052]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [1]}]}\n",
      "----------done-----------\n",
      "load state_dict successfully\n",
      "{'state': {0: {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
      "        [0.0052, 0.0052]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [1]}]}\n",
      "\n",
      "{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False}\n",
      "\n",
      "defaultdict(<class 'dict'>, {tensor([[-0.4442, -0.7888],\n",
      "        [-1.7508, -0.0942]], requires_grad=True): {'momentum_buffer': tensor([[0.0052, 0.0052],\n",
      "        [0.0052, 0.0052]])}})\n",
      "\n",
      "[{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [tensor([[-0.4442, -0.7888],\n",
      "        [-1.7508, -0.0942]], requires_grad=True)]}, {'lr': 0.0001, 'nesterov': True, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'params': [tensor([[ 0.0042, -0.5098, -1.4636],\n",
      "        [-0.1872,  0.1309,  0.8817],\n",
      "        [-0.7516, -0.5788,  1.9815]], requires_grad=True)]}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# 设置权重，服从正态分布  --> 2 x 2\n",
    "weight = torch.randn((2, 2), requires_grad=True)\n",
    "# 设置梯度为全1矩阵  --> 2 x 2\n",
    "weight.grad = torch.ones((2, 2))\n",
    "# 输出现有的weight和data\n",
    "print(\"The data of weight before step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight before step:\\n{}\".format(weight.grad))\n",
    "# 实例化优化器\n",
    "optimizer = torch.optim.SGD([weight], lr=0.1, momentum=0.9)\n",
    "# 进行一步操作\n",
    "optimizer.step()\n",
    "# 查看进行一步后的值，梯度\n",
    "print(\"The data of weight after step:\\n{}\".format(weight.data))\n",
    "print(\"The grad of weight after step:\\n{}\".format(weight.grad))\n",
    "# 权重清零\n",
    "optimizer.zero_grad()\n",
    "# 检验权重是否为0\n",
    "print(\"The grad of weight after optimizer.zero_grad():\\n{}\".format(weight.grad))\n",
    "# 输出参数\n",
    "print(\"optimizer.params_group is \\n{}\".format(optimizer.param_groups))\n",
    "# 查看参数位置，optimizer和weight的位置一样，我觉得这里可以参考Python是基于值管理\n",
    "print(\"weight in optimizer:{}\\nweight in weight:{}\\n\".format(id(optimizer.param_groups[0]['params'][0]), id(weight)))\n",
    "# 添加参数：weight2\n",
    "weight2 = torch.randn((3, 3), requires_grad=True)\n",
    "optimizer.add_param_group({\"params\": weight2, 'lr': 0.0001, 'nesterov': True})\n",
    "# 查看现有的参数\n",
    "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups))\n",
    "# 查看当前状态信息\n",
    "opt_state_dict = optimizer.state_dict()\n",
    "print(\"state_dict before step:\\n\", opt_state_dict)\n",
    "# 进行5次step操作\n",
    "for _ in range(50):\n",
    "    optimizer.step()\n",
    "# 输出现有状态信息\n",
    "print(\"state_dict after step:\\n\", optimizer.state_dict())\n",
    "# 保存参数信息\n",
    "torch.save(optimizer.state_dict(),os.path.join(r\"Attention_Unet\", \"optimizer_state_dict.pkl\"))\n",
    "print(\"----------done-----------\")\n",
    "# 加载参数信息\n",
    "state_dict = torch.load(r\"Attention_Unet\\optimizer_state_dict.pkl\") # 需要修改为你自己的路径\n",
    "optimizer.load_state_dict(state_dict)\n",
    "print(\"load state_dict successfully\\n{}\".format(state_dict))\n",
    "# 输出最后属性信息\n",
    "print(\"\\n{}\".format(optimizer.defaults))\n",
    "print(\"\\n{}\".format(optimizer.state))\n",
    "print(\"\\n{}\".format(optimizer.param_groups))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be203ce0b3afc4f5c37fbac412025d7ed1d67cabe9dd00b1fc8774c6d6d19d70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
